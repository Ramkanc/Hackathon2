{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramkanc/Hackathon2/blob/main/Ram_V2_Hackathon2_Voice_E_commerce_Ordering_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZIubkln0AI2"
      },
      "source": [
        "# Advanced Certification in AIML\n",
        "## A Program by IIIT-H and TalentSprint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alui-GbzEBtW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "14f109bc-6780-4425-ea6c-9d719c549760"
      },
      "source": [
        "#@title Explanation Video\n",
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<video width=\"720\" and height=\"400\" controls>\n",
        "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Hackathon_Voice_based.mp4\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video width=\"720\" and height=\"400\" controls>\n",
              "  <source src=\"https://cdn.iiith.talentsprint.com/aiml/Experiment_related_data/Walkthrough/Hackathon_Voice_based.mp4\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LNbxek40AI4"
      },
      "source": [
        "# Hackathon: Voice commands based E-commerce ordering system\n",
        "The goal of the hackathon is to train your model on different types of voice data (such as studio data and your own team data) and able to place order based on user preferences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fms7Yt7byCuQ"
      },
      "source": [
        "## Grading = 40 Marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUtVl7cBHlIh"
      },
      "source": [
        "### **Objectives:**\n",
        "\n",
        "Stage 0 - Obtain Features from Audio samples\n",
        "\n",
        "Stage 1 (22 Marks) - Define and train a CNN model on Studio data and deploy the model in the server\n",
        "\n",
        "Stage 2 (18 Marks) - Collect your voice samples (team data) and refine the classifier trained on Studio_data. Deploy the model in the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYm_60PiPSsq"
      },
      "source": [
        "## Dataset Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiAu1XJx3lCJ"
      },
      "source": [
        "The data contains voice samples of classes - Zero, One, Two, Three, Four, Five. Each class is denoted by a numerical label from 0 to 5.\n",
        "\n",
        "The audio files collected in a Studio dataset contain very few noise samples and all the files are in wav format.\n",
        "\n",
        "The audio files recorded for the studio are saved with the following naming convention:\n",
        "\n",
        "● Class Representation + user_id + sample_ID (or noise + sample_ID)\n",
        "\n",
        "> For example: The voice sample by the user b2 recorded “Zero”, it is saved as 0_b2_35.wav. Here 35 is sample ID, 2 is the user id and ‘0’ is the label of that sample.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv0xxq_d0Qb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e98a8a7-05c1-4450-c800-9dd89ce3dda3"
      },
      "source": [
        "#@title Please run the setup to download the dataset\n",
        "\n",
        "from IPython import get_ipython\n",
        "ipython = get_ipython()\n",
        "\n",
        "notebook= \"Hackathon2 - Voice E-commerce Ordering System\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget https://cdn.iiith.talentsprint.com/aiml/Hackathon_data/B17_studio_rev_data.zip\")\n",
        "    ipython.magic(\"sx unzip B17_studio_rev_data.zip \")\n",
        "    print (\"Setup completed successfully\")\n",
        "\n",
        "setup()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqNBNvC25WNV"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import librosa\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from time import sleep\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEg2PYXrOjnZ"
      },
      "source": [
        "## **Stage 0:** Obtain Features from Audio samples\n",
        "---\n",
        "\n",
        "### Generate features from an audio sample of '.wav' format\n",
        "- Code is available to extract the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTtb2zAj5k0-"
      },
      "source": [
        "# Caution: Do not change the default parameters\n",
        "def get_features(filepath, sr=8000, n_mfcc=30, n_mels=128, frames = 15):\n",
        "    # The following function contains code to produce features of the audio sample.\n",
        "    y, sr = librosa.load(filepath, sr=sr)\n",
        "    D = np.abs(librosa.stft(y))**2\n",
        "    S = librosa.feature.melspectrogram(S=D)\n",
        "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    log_S = librosa.power_to_db(S,ref=np.max)\n",
        "    features = librosa.feature.mfcc(S=log_S, n_mfcc=n_mfcc)\n",
        "    if features.shape[1] < frames :\n",
        "        features = np.hstack((features, np.zeros((n_mfcc, frames - features.shape[1]))))\n",
        "    elif features.shape[1] > frames:\n",
        "        features = features[:, :frames]\n",
        "\n",
        "    # Find 1st order delta_mfcc\n",
        "    delta1_mfcc = librosa.feature.delta(features, order=1)\n",
        "\n",
        "    # Find 2nd order delta_mfcc\n",
        "    delta2_mfcc = librosa.feature.delta(features, order=2)\n",
        "\n",
        "    # Stacking delta_mfcc features in sequence horizontally (column wise)\n",
        "    features = np.hstack((delta1_mfcc.flatten(), delta2_mfcc.flatten()))\n",
        "\n",
        "    # Increase the dimension by inserting an axis along second dimension\n",
        "    features = features.flatten()[:,np.newaxis]\n",
        "\n",
        "    # Convert the numpy.ndarray to a Tensor object\n",
        "    features = Variable(torch.from_numpy(features)).float()\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhLFY4n6BwIj"
      },
      "source": [
        "All the voice samples needed for training are present in the folder `\"studio_data\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMF1AqHZhl1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9664b71-9130-4aec-fcfc-acde58610f11"
      },
      "source": [
        "%ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B17_studio_rev_data.zip  \u001b[0m\u001b[01;34msample_data\u001b[0m/  \u001b[01;34mstudio_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2AAbFp5KORl"
      },
      "source": [
        "##**Stage 1**:  Define and train a CNN model on Studio data and deploy the model in the server\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-LowDuCMUL"
      },
      "source": [
        "### a) Extract features of Studio data (4 Marks)\n",
        "\n",
        " Load 'Studio data' and extract mfcc features\n",
        "\n",
        " **Evaluation Criteria:**\n",
        "\n",
        " * Complete the code in the load_data function\n",
        " * The function should take path of the folder containing audio samples as input\n",
        " * It should return features of all the audio samples present in the specified folder into single array (list of lists or 2-d numpy array) and their respective labels should be returned too"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDzCa-532EUj"
      },
      "source": [
        "#def load_data(folder_path):\n",
        "    #YOUR CODE HERE\n",
        "    #return features, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(folder_path):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            filepath = os.path.join(folder_path, filename)\n",
        "            label = int(filename.split(\"_\")[0])\n",
        "            feature = get_features(filepath)\n",
        "            features.append(feature)\n",
        "            labels.append(label)\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "zo67Rrr-MJyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7673ezpxFEfM"
      },
      "source": [
        "Load data from studio_data folder for extracting all features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5CjrlPVPjNs"
      },
      "source": [
        "studio_recorded_features, studio_recorded_labels = load_data('/content/studio_data')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying normalization\n",
        "#studio_recorded_features = F.normalize(torch.stack(studio_recorded_features), p=2,  dim=1)"
      ],
      "metadata": {
        "id": "27d5Ox8vudvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krshAu69Hy8-"
      },
      "source": [
        "Use train_test_split for splitting the train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LV83ruiHvfO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# YOUR CODE HERE\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(studio_recorded_features, studio_recorded_labels, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43M0H5Z23rnh"
      },
      "source": [
        "Load the dataset with DataLoader\n",
        "- Refer to [torch.utils.data.TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset)\n",
        "- Refer to [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.stack(X_train), torch.tensor(y_train)) # torch.stack"
      ],
      "metadata": {
        "id": "7jwZ5DRGOXgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls6gI08XH2ak"
      },
      "source": [
        "# YOUR CODE HERE for the DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print tensor sizes of train_loader\n",
        "for batch_idx, (data, target) in enumerate(train_loader):\n",
        "  print(\"Data tensor size:\", data.size())\n",
        "  print(\"Target tensor size:\", target.size())\n",
        "  print(data[0].shape, \"\\n\", max(data[0]), min(data[0]))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-STWlzZadeVV",
        "outputId": "9edd1fd3-aa8d-48b8-a364-7b49319f8528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data tensor size: torch.Size([32, 900, 1])\n",
            "Target tensor size: torch.Size([32])\n",
            "torch.Size([900, 1]) \n",
            " tensor([69.0408]) tensor([-19.6773])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGq6XpvhFynP"
      },
      "source": [
        "### b) Define your CNN architecture (4 Marks)\n",
        "\n",
        "[Hint](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU5hdERsFw5o"
      },
      "source": [
        "## Define your CNN Architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Sample Convolution Layer 1\n",
        "        self.conv1 = nn.Conv1d(in_channels=900, out_channels=512, kernel_size=1)#,stride=1, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        # Sample Maxpool for the Convolutional Layer 1\n",
        "        self.maxpool1 = nn.MaxPool1d(1)\n",
        "        # Sample Dropout Layer\n",
        "        #self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        # YOUR CODE HERE for defining more number of Convolutional layers with Maxpool as required (Hint: Use at least 2 more convolutional layers for better performance)\n",
        "\n",
        "        #Convolution Layer 2\n",
        "        self.conv2 = nn.Conv1d(in_channels=512, out_channels=356, kernel_size=1)\n",
        "        self.bn2 = nn.BatchNorm1d(356)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool1d(1)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        # Convolution Layer 3\n",
        "        self.conv3 = nn.Conv1d(in_channels=356, out_channels=136, kernel_size=1)\n",
        "        self.bn3 = nn.BatchNorm1d(136)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.maxpool3 = nn.MaxPool1d(1)\n",
        "\n",
        "\n",
        "        # YOUR CODE HERE for defining the Fully Connected Layer and also define LogSoftmax\n",
        "\n",
        "\n",
        "        # Fully Connected Layer\n",
        "        self.fc1 = nn.Linear(136, 10)\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Convolution Layer 1, Maxpool and Dropout\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.maxpool1(out)\n",
        "        #out = self.dropout(out)\n",
        "        # YOUR CODE HERE for the Convolutional Layers and Maxpool based on the defined Convolutional layers\n",
        "\n",
        "        #Convolution Layer 2\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.maxpool2(out)\n",
        "        out = self.dropout(out)\n",
        "        # Convolution Layer 3\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "        out = self.relu3(out)\n",
        "        out = self.maxpool3(out)\n",
        "\n",
        "        # YOUR CODE HERE for flattening the output of the final pooling layer to a vector. Flattening is simply arranging the 3D volume of numbers into a 1D vector\n",
        "        # Flatten the output of the last pooling layer\n",
        "        #print(\"Size after conv3: \",out.shape)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        #print(\"Size after flatten: \",out.shape)\n",
        "\n",
        "        # YOUR CODE HERE for returning the output of LogSoftmax after applying Fully Connected Layer\n",
        "        # Fully Connected Layer and LogSoftmax\n",
        "        out = self.fc1(out)\n",
        "        out = self.logsoftmax(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OFWuGmq05ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684646c5-2553-4f4b-db9e-6e12ac8dd3c8"
      },
      "source": [
        "# To run the training on GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wkt8lKQtCIWD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f4e1d9-4da2-4ae4-cb88-f32c9afa6a48"
      },
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "print(model)\n",
        "\n",
        "#criterion = # YOUR CODE HERE : Explore and declare loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = # YOUR CODE HERE : Explore on the optimizer and define with the learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "schedulaer = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True, min_lr=1e-6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv1d(900, 512, kernel_size=(1,), stride=(1,))\n",
            "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv1d(512, 356, kernel_size=(1,), stride=(1,))\n",
            "  (bn2): BatchNorm1d(356, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (conv3): Conv1d(356, 136, kernel_size=(1,), stride=(1,))\n",
            "  (bn3): BatchNorm1d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu3): ReLU()\n",
            "  (maxpool3): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=136, out_features=10, bias=True)\n",
            "  (logsoftmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "PfyBdoGXSh7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (900, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfTE4yiOSrKl",
        "outputId": "646cca02-a765-480b-e5b8-03239ab3a9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv1d-1               [-1, 512, 1]         461,312\n",
            "       BatchNorm1d-2               [-1, 512, 1]           1,024\n",
            "              ReLU-3               [-1, 512, 1]               0\n",
            "         MaxPool1d-4               [-1, 512, 1]               0\n",
            "            Conv1d-5               [-1, 356, 1]         182,628\n",
            "       BatchNorm1d-6               [-1, 356, 1]             712\n",
            "              ReLU-7               [-1, 356, 1]               0\n",
            "         MaxPool1d-8               [-1, 356, 1]               0\n",
            "           Dropout-9               [-1, 356, 1]               0\n",
            "           Conv1d-10               [-1, 136, 1]          48,552\n",
            "      BatchNorm1d-11               [-1, 136, 1]             272\n",
            "             ReLU-12               [-1, 136, 1]               0\n",
            "        MaxPool1d-13               [-1, 136, 1]               0\n",
            "           Linear-14                   [-1, 10]           1,370\n",
            "       LogSoftmax-15                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 695,870\n",
            "Trainable params: 695,870\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.03\n",
            "Params size (MB): 2.65\n",
            "Estimated Total Size (MB): 2.69\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5nF5pwKQ2t1"
      },
      "source": [
        "### c) Train and classify on the studio_data (3 Marks)\n",
        "\n",
        "The goal here is to train the Model on voice samples collected in studio data and validate it continuously to calculate the loss and accuracy for the train dataset across each epoch.\n",
        "\n",
        "Iterate over images in the train_loader and perform the following steps.\n",
        "\n",
        "1. First, zero out the gradients using zero_grad()\n",
        "\n",
        "2. Pass the data to the model. Convert the data to GPU before passing data  to the model\n",
        "\n",
        "3. Calculate the loss using a Loss function\n",
        "\n",
        "4. Perform Backward pass using backward() to update the weights\n",
        "\n",
        "5. Optimize and predict by using the torch.max()\n",
        "\n",
        "6. Calculate the accuracy of the train dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ot89MxKavVy"
      },
      "source": [
        "# YOUR CODE HERE. This will take time\n",
        "\n",
        "# Record loss and accuracy of the train dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, zero out the gradients using zero_grad()\n",
        "# Pass the data to the model. Convert the data to GPU before passing data to the model\n",
        "# Calculate the loss using a Loss function\n",
        "# Perform Backward pass using backward() to update the weights\n",
        "# Optimize and predict by using the torch.max()\n",
        "# Calculate the accuracy of the train dataset\n",
        "\n",
        "num_epochs = 25\n",
        "\n",
        "train_losses, train_accuracis = [], []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Zero out the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass the data to the model\n",
        "        outputs = model(data)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimize\n",
        "        optimizer.step()\n",
        "\n",
        "        # Predict\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        train_total += target.size(0)\n",
        "        train_correct += (predicted == target).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracis.append(train_accuracy)\n",
        "    schedulaer.step(train_loss)\n",
        "    # Print the loss and accuracy for the epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Learning rate {optimizer.param_groups[0]['lr']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il4OSTgHecZl",
        "outputId": "1ae05e13-b4a1-47d7-a2bb-2e64db83d262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/25], Train Loss: 1.1803, Train Accuracy: 59.57%, Learning rate 0.001\n",
            "Epoch [2/25], Train Loss: 0.6728, Train Accuracy: 76.63%, Learning rate 0.001\n",
            "Epoch [3/25], Train Loss: 0.5240, Train Accuracy: 81.72%, Learning rate 0.001\n",
            "Epoch [4/25], Train Loss: 0.4331, Train Accuracy: 84.73%, Learning rate 0.001\n",
            "Epoch [5/25], Train Loss: 0.3829, Train Accuracy: 86.27%, Learning rate 0.001\n",
            "Epoch [6/25], Train Loss: 0.3253, Train Accuracy: 88.60%, Learning rate 0.001\n",
            "Epoch [7/25], Train Loss: 0.2999, Train Accuracy: 89.70%, Learning rate 0.001\n",
            "Epoch [8/25], Train Loss: 0.2196, Train Accuracy: 92.37%, Learning rate 0.001\n",
            "Epoch [9/25], Train Loss: 0.2170, Train Accuracy: 92.15%, Learning rate 0.001\n",
            "Epoch [10/25], Train Loss: 0.1908, Train Accuracy: 93.40%, Learning rate 0.001\n",
            "Epoch [11/25], Train Loss: 0.1558, Train Accuracy: 94.50%, Learning rate 0.001\n",
            "Epoch [12/25], Train Loss: 0.1853, Train Accuracy: 93.15%, Learning rate 0.001\n",
            "Epoch [13/25], Train Loss: 0.1333, Train Accuracy: 95.70%, Learning rate 0.001\n",
            "Epoch [14/25], Train Loss: 0.1567, Train Accuracy: 94.22%, Learning rate 0.001\n",
            "Epoch [15/25], Train Loss: 0.1260, Train Accuracy: 95.44%, Learning rate 0.001\n",
            "Epoch [16/25], Train Loss: 0.1008, Train Accuracy: 96.83%, Learning rate 0.001\n",
            "Epoch [17/25], Train Loss: 0.1312, Train Accuracy: 95.66%, Learning rate 0.001\n",
            "Epoch [18/25], Train Loss: 0.1405, Train Accuracy: 94.97%, Learning rate 0.001\n",
            "Epoch [19/25], Train Loss: 0.0875, Train Accuracy: 97.39%, Learning rate 0.001\n",
            "Epoch [20/25], Train Loss: 0.0876, Train Accuracy: 96.83%, Learning rate 0.001\n",
            "Epoch [21/25], Train Loss: 0.0838, Train Accuracy: 97.20%, Learning rate 0.001\n",
            "Epoch [22/25], Train Loss: 0.0697, Train Accuracy: 97.52%, Learning rate 0.001\n",
            "Epoch [23/25], Train Loss: 0.0801, Train Accuracy: 97.27%, Learning rate 0.001\n",
            "Epoch [24/25], Train Loss: 0.0692, Train Accuracy: 97.64%, Learning rate 0.001\n",
            "Epoch [25/25], Train Loss: 0.0697, Train Accuracy: 97.42%, Learning rate 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot trainloss vs train accuracy curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "epochs = range(1, num_epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(epochs, train_losses, label='Train Loss')\n",
        "plt.plot(epochs, train_accuracis, label='Train Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Train Loss vs Train Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9dANwt13RxpX",
        "outputId": "41ba639a-d1ad-4779-e78f-bd844dcfc3ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5BJIQzgHa0k"
      },
      "source": [
        "### d) Testing Evaluation for CNN model (3 Marks)\n",
        "\n",
        "Evaluate model with the given test data\n",
        "\n",
        "1. Transform and load the test images.\n",
        "\n",
        "2. Pass the test data through the model (network) to get the outputs\n",
        "\n",
        "3. Get the predictions from a maximum value using torch.max\n",
        "\n",
        "4. Compare with the actual labels and get the count of the correct labels\n",
        "\n",
        "5. Calculate the accuracy based on the count of correct labels\n",
        "\n",
        "### **Expected testing accuracy is above 80%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnKZ-gP-30xR"
      },
      "source": [
        "# YOUR CODE HERE to test the model\n",
        "test_data = TensorDataset(torch.stack(X_test), torch.tensor(y_test))\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform and load the test data.\n",
        "# Pass the test data through the model (network) to get the outputs\n",
        "# Get the predictions from a maximum value using torch.max\n",
        "# Compare with the actual labels and get the count of the correct labels\n",
        "# Calculate the accuracy based on the count of correct labels\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "test_accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjnBsVZmgOS4",
        "outputId": "5aaf48ec-d4ad-49ae-be2d-0f9bf1b24102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqIP3Y17byDq"
      },
      "source": [
        "### e) Save and download your model (2 Marks)\n",
        "\n",
        "**Save your model trained on studio data**\n",
        "\n",
        "* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n",
        "integrating model to the web application\n",
        "\n",
        " [Hint](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7KAIpLsI4Uj"
      },
      "source": [
        "### YOUR CODE HERE for saving the CNN model\n",
        "torch.save(model.state_dict(), 'studio_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsCHKXubHAJB"
      },
      "source": [
        "Download your trained model using the code below\n",
        "* Give the path of model file to download through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDmWXfPaHJZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "97383a24-f1d2-40af-e9ad-24f178c96782"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/studio_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ac45f1b3-6787-4bff-a39a-3ab2b97b0b9a\", \"studio_model.pth\", 2798680)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl3Ins3vSTQx"
      },
      "source": [
        "### f) Deploy and evaluate your model trained on Studio Data in the server (6 Marks).\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password provided by the mentors in the lab)\n",
        "\n",
        "Deploy your model on the server, check the hackathon document (2-Server Access and File transfer For Voice based e-commerce ordering.pdf) for details.\n",
        "\n",
        "To order product in user interface, go through the document (3-Hackathon_II Application Interface Documentation.pdf) for details.\n",
        "\n",
        "\n",
        "**Evaluation Criteria: Four consecutive utterances should be predicted correctly by the model**\n",
        "\n",
        "- There are two stages in the e-commerce ordering application    \n",
        "    - Ordering Product\n",
        "    - Selecting the e-commerce platform\n",
        "- If both the stages are cleared as per the evaluation criteria you will get\n",
        "complete marks Otherwise, you will see a reduction in the marks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIXBC0aYKhKX"
      },
      "source": [
        "## **Stage 2:** Collect your voice samples and refine the classifier trained on studio_data and Team_data\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSoJN11_kMR"
      },
      "source": [
        "### a) Collect your Team Voice Samples and extract features (6 Marks)\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password is given by mentors in the lab)\n",
        "\n",
        "* In order to collect the team data, ensure the server is active (2-Server Access and File transfer For Voice based e-commerce ordering.pdf)\n",
        "\n",
        "* Refer document \"3-Hackathon_II Application Interface Documentation.pdf\" for collecting your team voice samples. These will get stored in your server\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "* Load 'Team_data' and extract features\n",
        "* Combine features of team data with the extracted features of studio data\n",
        "* Split the combined features into train and test data\n",
        "* Load the dataset with DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv3I24flWlLq"
      },
      "source": [
        "!mkdir team_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB_bSllKWJ5U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdfa24c-bac9-4be0-e7d6-d6184941668b"
      },
      "source": [
        "# Replace <YOUR_GROUP_ID> with your Username given in the lab\n",
        "!wget -r -A .wav https://aiml-sandbox1.talentsprint.com/audio_recorder/<YOUR_GROUP_ID>/team_data/ -nH --cut-dirs=100  -P ./team_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: YOUR_GROUP_ID: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G17PFkgI02J"
      },
      "source": [
        "# YOUR CODE HERE to Load data from teamdata folder for extracting all features and labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_sh6DCbJKhg"
      },
      "source": [
        "# Combine the features of all voice samples (studio_data and teamdata)\n",
        "# YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcSfoU9hyst4"
      },
      "source": [
        "# YOUR CODE HERE to split the combined features into train and test data (Hint: Use train_test_split)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQ8gSTYg1dSp"
      },
      "source": [
        "# YOUR CODE HERE to load the dataset with DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSE9E9mDF7Az"
      },
      "source": [
        "### b) Classify and download the model (6 Marks)\n",
        "\n",
        "The goal here is to train and test your model on all voice samples collected in studio and team data\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "* Refine your classifier (if needed)\n",
        "* Train your model on the extracted train data\n",
        "* Test your model on the extracted test data\n",
        "* Save and download the trained model\n",
        "\n",
        "### **Expected testing accuracy is above 80%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1EtSEwDG-q4"
      },
      "source": [
        "# YOUR CODE HERE for refining your classifier (if needed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz0UbGJrz59Z"
      },
      "source": [
        "# YOUR CODE HERE to train your model\n",
        "\n",
        "# Record loss and accuracy of the train dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CkqFppJ0Fha"
      },
      "source": [
        "# YOUR CODE HERE to test your model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snSilDehQcKv"
      },
      "source": [
        "**Save your trained model**\n",
        "\n",
        "* Save the state dictionary of the classifier (use pytorch only), It will be useful in\n",
        "integrating model to the web application\n",
        "\n",
        " [Hint](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGiaYmCnQcKz"
      },
      "source": [
        "### YOUR CODE HERE for saving the CNN model\n",
        "torch.save(model.state_dict(), 'my_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TSFyHRFQcK1"
      },
      "source": [
        "Download your trained model using the code below\n",
        "* Give the path of model file to download through the browser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF2kGMjAQcK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "05dabbe2-47e6-4cb6-ec71-2782572403a6"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/my_model.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6168a1b9-878a-49f0-a94d-ca049c17cdec\", \"my_model.pth\", 2798572)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhmbXkFx6is"
      },
      "source": [
        "### c) Deploy and evaluate your model trained on Studio Data + Team Data in the server (6 Marks).\n",
        "\n",
        "(This can be done on the day of the Hackathon once the login username and password provided by the mentors in the lab)\n",
        "\n",
        "Deploy your model on the server, check the hackathon document (2-Server Access and File transfer For Voice based e-commerce ordering.pdf) for details.\n",
        "\n",
        "To order product in user interface, go through the document (3-Hackathon_II Application Interface Documentation.pdf) for details.\n",
        "\n",
        "\n",
        "**Evaluation Criteria: Four consecutive utterances should be predicted correctly by the model**\n",
        "\n",
        "- There are two stages in the e-commerce ordering application    \n",
        "    - Ordering Product\n",
        "    - Selecting the e-commerce platform\n",
        "- If both the stages are cleared as per the evaluation criteria you will get\n",
        "complete marks Otherwise, you will see a reduction in the marks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kIo3R5hQnrh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}